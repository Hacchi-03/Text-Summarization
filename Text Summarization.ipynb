{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attention in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (4.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from attention) (1.20.1)\n",
      "Requirement already satisfied: tensorflow>=2.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from attention) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (2.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (52.0.0.post20210125)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (2.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (20.9)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (0.27.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (1.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (22.10.26)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorflow>=2.1->attention) (1.50.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.1->attention) (0.36.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (2.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (3.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=2.1->attention) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from packaging->tensorflow>=2.1->attention) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "_Jpu8qLEFxcY",
    "outputId": "95968e01-faac-4911-c802-9c008a4e62cf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed,Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnK5o4Z1Fxcj"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/Sribalaji/Downloads/FOOD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Duplicates and NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cjul88oOFxcr"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__fy-JxTFxc9",
    "outputId": "d42c6e36-bbc8-43c2-de0e-d3effe3e8c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4919 entries, 0 to 4934\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      4919 non-null   int64 \n",
      " 1   ProductId               4919 non-null   object\n",
      " 2   UserId                  4919 non-null   object\n",
      " 3   ProfileName             4919 non-null   object\n",
      " 4   HelpfulnessNumerator    4919 non-null   int64 \n",
      " 5   HelpfulnessDenominator  4919 non-null   int64 \n",
      " 6   Score                   4919 non-null   int64 \n",
      " 7   Time                    4919 non-null   int64 \n",
      " 8   Summary                 4919 non-null   object\n",
      " 9   Text                    4919 non-null   object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 422.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6IY-x2FxdL"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZr-u3OEFxdT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sribalaji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                \n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2QAeCHWFxdY"
   },
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCAIkhWbFxdh",
    "outputId": "c2da1a36-4488-4e32-ef9e-fcfe496e374d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsRXocxoFxd-"
   },
   "outputs": [],
   "source": [
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQJdZcAzFxee",
    "outputId": "a1fbe683-c03f-4afb-addf-e075021c121b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1zLpnqsFxey"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYK390unFxfA"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdF76AHHFxgw",
    "outputId": "e3bbe165-4235-482f-bfd4-36a3f1d95290"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JRjwdIOFxg3",
    "outputId": "f968be82-c539-471d-ce23-16f18b059ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9452807160292921\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKD5VOWqFxhC"
   },
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY0tEJP0FxhI"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwLUH78CFxhg"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RakakKHcFxhl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRHTgX6hFxhq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8KronV2Fxhx",
    "outputId": "d2eb2f27-fbbc-4e61-9556-3c3ff5e4327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 69.88013698630137\n",
      "Total Coverage of rare words: 12.449877538634935\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2giEsF3Fxh3"
   },
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCbGMsm4FxiA",
    "outputId": "2d9165f0-e542-4114-91f3-e070d483fce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1760"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQfKP3sqRxi9"
   },
   "source": [
    "# Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRHqyBkBFxiJ"
   },
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzE5OiRLFxiM",
    "outputId": "7f7a4f89-b088-4847-8172-09e5a2383d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 87.24002248454188\n",
      "Total Coverage of rare words: 18.914040761073927\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fswLvIgFxiR"
   },
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR8IX9FRFxiY",
    "outputId": "b116cdbd-42c4-4ede-9f6d-46284115393e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2540, 2540)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-vW82sFxih"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx5NISuMFxik"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-attention in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (1.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: keras in c:\\users\\sribalaji\\documents\\me\\lib\\site-packages (from keras-attention) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "pip install keras-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXef38nBFxir",
    "outputId": "7ae99521-46f8-4c6f-9cba-4979deffeee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 30, 100)      176000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 30, 300),    481200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 30, 300),    721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    22800       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 30, 300),    721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (AttentionLaye  ((None, None, 300),  180300     ['lstm_2[0][0]',                 \n",
      " r)                              (None, None, 30))                'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 600)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 228)   137028      ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,920,928\n",
      "Trainable params: 2,920,928\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "from tensorflow.keras.layers import Attention,Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from attention import AttentionLayer\n",
    "K.clear_session()\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lwfi1Fm8Fxiz"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-A3J92MUljB"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETnPzA4OFxi3",
    "outputId": "477e374f-7cf2-4d60-f86e-2c49c9cebedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=5,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDTNLAURFxjE",
    "outputId": "e2ea6e44-3931-4014-97a1-03fa2a441228"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBX0zZnOFxjW"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QkrNV-4Fxjt"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f6TTFnBFxj6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        e_h, e_c = h, c\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAUntznIFxj9"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: stevia best tasting ever tried also mixes others service buyer prompt product arrived time excellent condition would order recommend others \n",
      "Original summary: the best \n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 790ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: best taste pasta cooks well slightly less time typical produced pasta nice color excellent \n",
      "Original summary: wow excellent \n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: far canned soups go ok disappointed texture extra bits overall quality spoiled living maine years tried different brands canned bisque come lobster bisque best made fresh \n",
      "Original summary: as as canned go \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted summary:  food\n",
      "\n",
      "\n",
      "Review: unless really really really like vinegar avoid chips called vinegar sea salt sea salt vinegar \n",
      "Original summary: awful taste \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love san tomatoes great greatest taste ever worth ever penny \n",
      "Original summary: the best \n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: gf diet months used new product old quality company excellent results still use variety box goes long way little expensive worth \n",
      "Original summary: bisquick good \n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: impressed flavors flavors sure going like really good also flavors intense getting bland chip monthly plan already order schedule twice \n",
      "Original summary: excellent \n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: stuff amazing fast shipping best tasting sugar free low calorie item market use coffee real treat thank ordering soon \n",
      "Original summary: love it \n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: four dogs love stuff bite size treat perfect size training dogs like crunch like small square enough huge bag make little gift bags friends dogs \n",
      "Original summary: our dogs go for this \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: enjoy selection met expectations far sister try favor milk chocolate glad brought variety pack anyway \n",
      "Original summary: good cocoa \n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tastes like drinking cherry pie purchased mother told works quickly also supposed help lower blood delivery stars high price \n",
      "Original summary: cheaper than \n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love stuff get amazon arrived time good condition enjoy \n",
      "Original summary: great calorie \n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: popchips excellent excellent flavor low calories eat need another potato chip \n",
      "Original summary: popchips \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: ordered candies first time hooked hint rose flavor overwhelming really enjoy highly recommended unique candy \n",
      "Original summary: these are \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: delicious nutritious live coconut nut treats since eat grains want pick bag whole foods local health store average around unless sale would able buy bulk yum yum \n",
      "Original summary: these are amazing \n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: think favorite cookies ever really light creamy bad longer find anywhere less two count think need many \n",
      "Original summary: best \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: great rich taste remember ground whole leaf tea stronger may expect overly sweet readily use mixed ice water bottle \n",
      "Original summary: great taste and convenient \n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: greatest best chocolate taste keurig cups definitely order everyone office chocolate nut pass test \n",
      "Original summary: the best chocolate taste out there \n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tea good discovered california got home searched local stores able find finally decided see amazon bought two boxes long make buy \n",
      "Original summary: tastes very good \n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: looking tired going store pick always sold love flavor sweet right thank buying \n",
      "Original summary: perfect \n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: like brew cup cocoa coffee nice mocha dark chocolate flavor quite nice especially mixed double black coffee though best good price right compared brands \n",
      "Original summary: not bad for the price \n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: tea tastes great helped cravings dieting tea inexpensive came packaged pretty box bags throw bag tea ball continue keep hand part tea collection \n",
      "Original summary: is \n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: mixed whipped cream blueberries lemon delicious easy quick dessert delight guests \n",
      "Original summary: easy \n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: could give product minus stars would strong product one us yet already avoid product others \n",
      "Original summary: like the product \n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: chips tasty low calorie gluten free great option go snack love \n",
      "Original summary: great snack \n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: prefer coffee husband like quite strong works well way made work makes cup half also makes kcup last twice long \n",
      "Original summary: green cups \n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: grove absolute best hot chocolate keurig always hot chocolate available away days \n",
      "Original summary: love this hot chocolate for the keurig \n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: thank product use time appreciate price excellent thanks \n",
      "Original summary: great product \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: chips tasty expected low salt item seem salty regular potato chip also seem greasy reduced fat chips less salty least much potato flavor far less greasy \n",
      "Original summary: not low salt \n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: bought juice really like great refreshing smooth beverage everybody family enjoy buy \n",
      "Original summary: nice sweet \n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: made cupcakes vanilla cake mix ok dense overly bad flavor however disappointed vanilla flavor subtle missed felt like needed little sweetness child made ate \n",
      "Original summary: could have better \n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: live without kitchen making cup coffee really easy especially need stay late hours sleep like making tea tastes decent enough starbucks good enough sugar cream \n",
      "Original summary: convenient \n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: chip addict far tastiest non homemade chips ever plus healthy problem cannot flavor favorite \n",
      "Original summary: yum \n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: really love snacks low calories fat high protein important \n",
      "Original summary: yummy \n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: green tea good antioxidants never quite taste lemon ginger give nice flavor great add packet water bottle go without bother brewing \n",
      "Original summary: easy and tasty for better health \n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: good frozen lemon juice good slightly odd flavor perhaps sure wish could order frozen juice \n",
      "Original summary: juice from amazon \n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: product works advertised told way mic computer either expensive box usb mic love little would definitely recommend friend \n",
      "Original summary: works perfect \n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: eat many chips love great buy arrived quick packed great expiration date ways away awhile enjoy great natural potato flavor love brown flavor fit description \n",
      "Original summary: great chip \n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: smooth taste taste good regular coffee usually coffee dinner never really decaf dinner alternative flavor \n",
      "Original summary: very smooth and \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good stuff like need small feel good mouth \n",
      "Original summary: beans \n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: popchips nice alternative potato chips greasy calories per bag great low calorie diet definitely would recommend trying least \n",
      "Original summary: great tasting \n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good texture crunchy flavor taste like potato chips opened bag would stale taste many others odd flavor well healthy good dieting low oil low buying \n",
      "Original summary: healthy good flavor \n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: one favorites smooth rich strong morning also bold enough like cup problem never find locally almost always get online usually expensive tried substitute like one quite much mahogany \n",
      "Original summary: like it but hard to find \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: product complete disappointment tastes like pineapple taste \n",
      "Original summary: tastes like \n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: root aid high blood drink pretty much given coffee drinking tasty substitute though one must taste home use bulk roasted root tea bags fantastic travel \n",
      "Original summary: my go to coffee \n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: happy product taste test price high delivery prompt expected \n",
      "Original summary: great \n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: favorite tea drink year round never get tired like others good time day strong still nicely flavorful good balance spicy herbal \n",
      "Original summary: favorite tea \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: husband twizzlers addict bought many times amazon living cannot get country always fresh tasty packed well arrive timely manner \n",
      "Original summary: fresh \n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: never sea salt sodium free got taste really like perhaps used regularly would want go back perhaps salt came around world might taste different well \n",
      "Original summary: taste that needs to be \n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: love chips even like black beans tasty yum plus good \n",
      "Original summary: delicious and \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: exactly ordered fuss arrived time pretty much ideal thing threw quantity \n",
      "Original summary: what ordered \n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: started outside house started feeding rather buying smaller bags great value cats love food always look forward eating shipped right door cannot go wrong \n",
      "Original summary: great value \n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: best eat day go quickly going tell many ive bought since year great love \n",
      "Original summary: love them get \n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: love product best natural sweetener ever tried tried many use also pancake syrup substitute honey peanut butter honey sandwich last long time good value \n",
      "Original summary: the best \n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love bread mixes nothing like making bread admit use bread maker enough use hands still enjoy experience tried different hodgson mixes excellent \n",
      "Original summary: excellent bread mix \n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: chips good sprinkle salad use cookies baking sprinkle cereal pleased \n",
      "Original summary: chips \n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good value also nicely thin easy use spread stuff \n",
      "Original summary: best value \n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: chips great substitute usual high calorie ones offered keep hand aid weight loss \n",
      "Original summary: great product \n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: favorite soup since childhood pleased find available amazon com reasonable price plan keep good supply hand times \n",
      "Original summary: it really is good \n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: coffee cannot say much perfect bitter perfect dark coffee \n",
      "Original summary: one of the best have ever had \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: sauce good anything like adding asian food anything egg noodles good burn strong flavor im hoping see flavors like pineapple soon buy wont \n",
      "Original summary: this sauce is the \n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: potatoes really good husband love way easy buying \n",
      "Original summary: so good \n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: product taste stale full artificial ingredients real peppermint product honest doesnt even taste like real cocoa either \n",
      "Original summary: not quality at all \n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: son loves best earth baby food favorite seems vegetable turkey every would recommend product anyone looking healthy feeding organic way food feed son earth best \n",
      "Original summary: product \n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: know ordering biscuit crumbs exactly received product amazon fault shipping products never order food amazon com ever \n",
      "Original summary: new amazon \n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: purchased hot cocoa cups find grove square best usually add two flavored favorite sugar free caramel adding sugar free creamer taste calories \n",
      "Original summary: great taste \n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: idea good caramel flavors ginger chocolate orange honey varieties missed mix rich dairy flavor sugar expect \n",
      "Original summary: not for \n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love jalapeno chips kettle must try nice kick jalapeno delicious addicting recommended \n",
      "Original summary: and spicy \n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: using cooking plus years roland extra purchased best ever used including bought italy back usa \n",
      "Original summary: an excellent product \n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: product hot sausage jar say hot sausage even warm sausage flavor serving type products year know talking \n",
      "Original summary: hot \n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: best hot cocoa found far hope find better real wish bit sweeter whole would buy cannot find better \n",
      "Original summary: it is ok best have so \n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: tea anything issues itching everything else enjoy smell say last hours \n",
      "Original summary: did not do nothing \n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: great gift bought couple friends loved came packaged ready gift would totally recommend \n",
      "Original summary: great gift \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: discovered pop chips yet know missing low calorie high flavor great kids lunches need single servings eat whole big bag \n",
      "Original summary: pop chips on the go \n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: took one two get used taste hooked keep bottle hand \n",
      "Original summary: mix \n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: favorite chips light crisp greasy flavor love great chips hard find \n",
      "Original summary: good \n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: dog allergy corn live small town found dog food contain mainly corn perfect new pet well loves added comes straight door \n",
      "Original summary: for dogs with special needs \n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  best\n",
      "\n",
      "\n",
      "Review: gum absolute favorite purchasing amazon get large good price highly recommend gum plus enjoy peppermint flavor breath teeth time \n",
      "Original summary: white is the best \n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good hot chocolate creamy tasty flavors good favorite peppermint wish peppermint available variety pack son also like add peppermint flavored marshmallows extra shot peppermint taste opinion better swiss miss cups \n",
      "Original summary: yummy \n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good idea raw sugar type cubes cost raw sugar \n",
      "Original summary: too \n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love popcorn shipping packing cost almost much popcorn need pack better bag split loose popcorn box guy brought door \n",
      "Original summary: good popcorn \n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: cats love food money great product get every month cats love flavor \n",
      "Original summary: great deal \n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-0e69bf8de83c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Review:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original summary:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted summary:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-33e4a3048b7b>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutput_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0me_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0msampled_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreverse_target_word_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\me\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "How to build own text summarizer using deep learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
